import os
import tempfile
import torch
import re
from funasr import AutoModel
from typing import Optional, Dict, Any, List

class ASRTranscriber:
    """
    åŸºäºFunASRçš„è¯­éŸ³è½¬æ–‡å­—è½¬å½•å™¨
    """
    
    def __init__(self, model_name="iic/SenseVoiceSmall", vad_model="fsmn-vad", device="auto", enable_vad=True):
        """
        åˆå§‹åŒ–ASRè½¬å½•å™¨
        
        Args:
            model_name (str): ASRæ¨¡å‹åç§°
            vad_model (str): VAD(è¯­éŸ³æ´»åŠ¨æ£€æµ‹)æ¨¡å‹åç§°
            device (str): è®¾å¤‡ç±»å‹ ("cpu", "cuda", "mps", "auto")
            enable_vad (bool): æ˜¯å¦å¯ç”¨VAD (é»˜è®¤: True)
        """
        self.model_name = model_name
        self.vad_model = vad_model if enable_vad else None
        self.enable_vad = enable_vad
        self.device = self._get_optimal_device(device)
        self.model = None
        self._load_model()
    
    def _get_optimal_device(self, device: str) -> str:
        """
        è·å–æœ€ä¼˜è®¡ç®—è®¾å¤‡
        
        Args:
            device (str): ç”¨æˆ·æŒ‡å®šçš„è®¾å¤‡æˆ–"auto"
            
        Returns:
            str: æœ€ä¼˜è®¾å¤‡åç§°
        """
        if device != "auto":
            return device
        
        # è‡ªåŠ¨æ£€æµ‹æœ€ä½³è®¾å¤‡
        if torch.cuda.is_available():
            print("ğŸš€ æ£€æµ‹åˆ°CUDA GPUï¼Œä½¿ç”¨GPUåŠ é€Ÿ")
            return "cuda"
        elif hasattr(torch.backends, 'mps') and torch.backends.mps.is_available():
            print("ğŸš€ æ£€æµ‹åˆ°Apple GPUï¼ˆMPSï¼‰ï¼Œä½¿ç”¨GPUåŠ é€Ÿ")
            return "mps"
        else:
            print("ğŸ’» ä½¿ç”¨CPUè®¡ç®—")
            return "cpu"
    
    def _load_model(self):
        """
        åŠ è½½ASRæ¨¡å‹
        """
        try:
            print(f"æ­£åœ¨åŠ è½½æ¨¡å‹: {self.model_name}...")
            if self.enable_vad:
                print("VADå·²å¯ç”¨ï¼Œå°†ä½¿ç”¨æ™ºèƒ½è¯­éŸ³åˆ†æ®µ")
                self.model = AutoModel(
                    model=self.model_name,
                    vad_model=self.vad_model,
                    vad_kwargs={"max_single_segment_time": 15000},  # VADé…ç½®ï¼Œ15ç§’åˆ†æ®µ
                    device=self.device
                )
            else:
                print("VADå·²ç¦ç”¨ï¼Œå°†æ•´ä½“å¤„ç†éŸ³é¢‘")
                self.model = AutoModel(
                    model=self.model_name,
                    device=self.device
                )
            print("æ¨¡å‹åŠ è½½æˆåŠŸï¼")
        except Exception as e:
            raise Exception(f"æ¨¡å‹åŠ è½½å¤±è´¥: {str(e)}")
    
    def transcribe_audio(self, audio_path: str, language: str = "auto", max_length: int = 1800, batch_size: int = 8) -> Dict[str, Any]:
        """
        è½¬å½•éŸ³é¢‘æ–‡ä»¶ - ä½¿ç”¨FunASRå†…ç½®æ™ºèƒ½åˆ†æ®µ
        
        Args:
            audio_path (str): éŸ³é¢‘æ–‡ä»¶è·¯å¾„
            language (str): è¯­è¨€ä»£ç  ("auto", "zh", "en", "ja", "ko" ç­‰)
            max_length (int): VADåˆ†æ®µæœ€å¤§é•¿åº¦(ç§’)ï¼Œç”¨äºmerge_length_så‚æ•°
            batch_size (int): æ‰¹å¤„ç†å¤§å°
        
        Returns:
            Dict[str, Any]: è½¬å½•ç»“æœ
        """
        if not os.path.exists(audio_path):
            raise FileNotFoundError(f"éŸ³é¢‘æ–‡ä»¶ä¸å­˜åœ¨: {audio_path}")
        
        if self.model is None:
            raise Exception("æ¨¡å‹æœªæ­£ç¡®åŠ è½½")
        
        # è·å–éŸ³é¢‘ä¿¡æ¯ç”¨äºä¼˜åŒ–å‚æ•°
        audio_info = self._get_audio_info(audio_path)
        print(f"éŸ³é¢‘æ—¶é•¿: {audio_info['duration']:.1f}ç§’ï¼Œä½¿ç”¨FunASRæ™ºèƒ½åˆ†æ®µå¤„ç†")
        
        try:
            print(f"æ­£åœ¨è½¬å½•éŸ³é¢‘æ–‡ä»¶: {audio_path}")
            
            # ä½¿ç”¨ä¼ å…¥çš„batch_sizeä½œä¸ºbatch_size_sï¼ˆåŠ¨æ€æ‰¹å¤„ç†ç§’æ•°ï¼‰
            # å¦‚æœbatch_sizeè¾ƒå°ï¼Œæ‰©å¤§åˆ°åˆç†å€¼ä»¥æé«˜æ•ˆç‡
            batch_size_s = min(batch_size, 6000)  # æœ€å¤§6000ç§’æ‰¹å¤„ç†
            # è®¾ç½®åˆç†çš„åˆå¹¶é•¿åº¦ï¼Œé¿å…ç‰‡æ®µè¿‡çŸ­
            merge_length_s = min(max_length, 30)
            
            print(f"ä½¿ç”¨å‚æ•°: batch_size_s={batch_size_s}, merge_length_s={merge_length_s}")
            
            # æ‰§è¡Œè½¬å½•ï¼Œä½¿ç”¨FunASRå†…ç½®æ™ºèƒ½åˆ†æ®µ
            result = self.model.generate(
                input=audio_path,
                language=language if language != "auto" else None,
                batch_size_s=batch_size_s,    # åŠ¨æ€æ‰¹å¤„ç†å¤§å°(ç§’)
                hotword=None,                 # çƒ­è¯å¢å¼º
                use_itn=True,                # ä½¿ç”¨é€†æ–‡æœ¬è§„èŒƒåŒ–
                output_timestamp=True,        # å¯ç”¨æ—¶é—´æˆ³è¾“å‡º
                merge_vad=False,             # é»˜è®¤ä¸å¯ç”¨VADåˆå¹¶
                # merge_length_s=merge_length_s, # VADç‰‡æ®µåˆå¹¶é•¿åº¦
                return_raw_text=True         # è¿”å›åŸå§‹æ–‡æœ¬
            )
            
            # å¤„ç†ç»“æœ
            if isinstance(result, list) and len(result) > 0:
                transcription_result = result[0]
                
                # è°ƒè¯•ï¼šæ£€æŸ¥æ˜¯å¦æˆåŠŸè·å–æ—¶é—´æˆ³
                if self.device != "cpu":  # åªåœ¨éCPUæ¨¡å¼ä¸‹æ˜¾ç¤ºè¯¦ç»†ä¿¡æ¯
                    timestamps = transcription_result.get("timestamp", [])
                    words = transcription_result.get("words", [])
                    print(f"è·å–åˆ° {len(timestamps)} ä¸ªæ—¶é—´æˆ³ï¼Œ{len(words)} ä¸ªè¯æ±‡")
                
                # æ¸…ç†æ–‡æœ¬ä¸­çš„æ ‡è®°ç¬¦å·
                raw_text = transcription_result.get("text", "")
                cleaned_text = self._clean_text(raw_text)
                
                # å¤„ç†æ—¶é—´æˆ³å’Œåˆ†è¯ä¿¡æ¯
                timestamps = transcription_result.get("timestamp", [])
                words = transcription_result.get("words", [])
                
                # ç”Ÿæˆå¸¦æ—¶é—´æˆ³çš„segments
                cleaned_segments = self._create_segments_from_timestamps(cleaned_text, timestamps, words)
                
                return {
                    "success": True,
                    "text": cleaned_text,
                    "segments": cleaned_segments,
                    "language": transcription_result.get("language", "unknown"),
                    "duration": transcription_result.get("duration", 0),
                    "confidence": transcription_result.get("confidence", 0)
                }
            else:
                return {
                    "success": False,
                    "error": "æœªè·å–åˆ°è½¬å½•ç»“æœ",
                    "text": "",
                    "segments": []
                }
                
        except Exception as e:
            return {
                "success": False,
                "error": f"è½¬å½•å¤±è´¥: {str(e)}",
                "text": "",
                "segments": []
            }
    
    def transcribe_with_timestamps(self, audio_path: str, language: str = "auto", max_length: int = 1800, batch_size: int = 8) -> Dict[str, Any]:
        """
        è½¬å½•éŸ³é¢‘å¹¶è¿”å›å¸¦æ—¶é—´æˆ³çš„ç»“æœ
        
        Args:
            audio_path (str): éŸ³é¢‘æ–‡ä»¶è·¯å¾„
            language (str): è¯­è¨€ä»£ç 
            max_length (int): æœ€å¤§å¤„ç†é•¿åº¦(ç§’)ï¼Œè¶…è¿‡å°†åˆ†æ®µå¤„ç†
            batch_size (int): æ‰¹å¤„ç†å¤§å°
        
        Returns:
            Dict[str, Any]: å¸¦æ—¶é—´æˆ³çš„è½¬å½•ç»“æœ
        """
        result = self.transcribe_audio(audio_path, language, max_length, batch_size)
        
        if result["success"] and result["segments"]:
            formatted_segments = []
            for i, segment in enumerate(result["segments"]):
                if isinstance(segment, dict):
                    formatted_segments.append({
                        "index": i + 1,
                        "start_time": segment.get("start", 0),
                        "end_time": segment.get("end", 0),
                        "text": segment.get("text", ""),
                        "confidence": segment.get("confidence", 0)
                    })
                else:
                    # å¦‚æœsegmentæ˜¯å­—ç¬¦ä¸²ï¼Œåˆ›å»ºä¸€ä¸ªç®€å•çš„ç»“æ„
                    formatted_segments.append({
                        "index": i + 1,
                        "start_time": 0,
                        "end_time": 0,
                        "text": str(segment),
                        "confidence": 0
                    })
            
            result["formatted_segments"] = formatted_segments
        
        return result
    
    def _clean_text(self, text: str) -> str:
        """
        æ¸…ç†æ–‡æœ¬ä¸­çš„æ ‡è®°ç¬¦å·
        
        Args:
            text (str): åŸå§‹æ–‡æœ¬
            
        Returns:
            str: æ¸…ç†åçš„æ–‡æœ¬
        """
        if not text:
            return ""
        
        # ç§»é™¤å„ç§æ ‡è®°ç¬¦å·
        # åŒ¹é…æ¨¡å¼ï¼š<|...| >
        cleaned_text = re.sub(r'<\|[^|]*\|>', '', text)
        
        # ç§»é™¤å¤šä½™çš„ç©ºæ ¼
        cleaned_text = re.sub(r'\s+', ' ', cleaned_text)
        
        # ç§»é™¤é¦–å°¾ç©ºæ ¼
        cleaned_text = cleaned_text.strip()
        
        return cleaned_text
    
    def _clean_segments(self, segments: List[Any]) -> List[Any]:
        """
        æ¸…ç†segmentsä¸­çš„æ–‡æœ¬æ ‡è®°
        
        Args:
            segments (List[Any]): åŸå§‹segments
            
        Returns:
            List[Any]: æ¸…ç†åçš„segments
        """
        cleaned_segments = []
        
        for segment in segments:
            if isinstance(segment, dict):
                # å¤åˆ¶segmentå­—å…¸
                cleaned_segment = segment.copy()
                # æ¸…ç†textå­—æ®µ
                if "text" in cleaned_segment:
                    cleaned_segment["text"] = self._clean_text(cleaned_segment["text"])
                cleaned_segments.append(cleaned_segment)
            else:
                # å¦‚æœæ˜¯å­—ç¬¦ä¸²ï¼Œç›´æ¥æ¸…ç†
                cleaned_segments.append(self._clean_text(str(segment)))
        
        return cleaned_segments
    
    def _clean_segments_with_timestamps(self, segments: List[Any]) -> List[Any]:
        """
        æ¸…ç†segmentsä¸­çš„æ–‡æœ¬æ ‡è®°ï¼Œä¿ç•™æ—¶é—´æˆ³ä¿¡æ¯
        
        Args:
            segments (List[Any]): åŸå§‹segments
            
        Returns:
            List[Any]: æ¸…ç†åçš„segmentsï¼Œä¿ç•™æ—¶é—´æˆ³
        """
        cleaned_segments = []
        
        for segment in segments:
            if isinstance(segment, dict):
                # å¤åˆ¶segmentå­—å…¸ï¼Œä¿ç•™æ‰€æœ‰æ—¶é—´æˆ³ä¿¡æ¯
                cleaned_segment = segment.copy()
                # æ¸…ç†textå­—æ®µ
                if "text" in cleaned_segment:
                    cleaned_segment["text"] = self._clean_text(cleaned_segment["text"])
                # ä¿ç•™æ—¶é—´æˆ³å­—æ®µï¼šstart, end, timestampç­‰
                cleaned_segments.append(cleaned_segment)
            else:
                # å¦‚æœæ˜¯å­—ç¬¦ä¸²ï¼Œè½¬æ¢ä¸ºå­—å…¸æ ¼å¼
                cleaned_segments.append({
                    "text": self._clean_text(str(segment)),
                    "start": None,
                    "end": None
                })
        
        return cleaned_segments
    
    def _create_segments_from_timestamps(self, text: str, timestamps: List[List[int]], words: List[str]) -> List[Dict[str, Any]]:
        """
        ä»æ—¶é—´æˆ³å’Œè¯æ±‡ä¿¡æ¯åˆ›å»ºsegments
        
        Args:
            text (str): æ¸…ç†åçš„æ–‡æœ¬
            timestamps (List[List[int]]): æ—¶é—´æˆ³åˆ—è¡¨ï¼Œä»¥æ¯«ç§’ä¸ºå•ä½
            words (List[str]): è¯æ±‡åˆ—è¡¨
            
        Returns:
            List[Dict[str, Any]]: å¸¦æ—¶é—´æˆ³çš„segments
        """
        if not timestamps or not words or len(timestamps) != len(words):
            return []
        
        # æŒ‰å¥å­åˆ†ç»„æ—¶é—´æˆ³
        segments = []
        current_segment = {
            "text": "",
            "start": None,
            "end": None,
            "words": []
        }
        
        for i, (word, timestamp) in enumerate(zip(words, timestamps)):
            # è·³è¿‡æ ‡è®°ç¬¦å·
            if word.startswith('<|') and word.endswith('|>'):
                continue
                
            start_ms, end_ms = timestamp
            start_sec = start_ms / 1000.0
            end_sec = end_ms / 1000.0
            
            # è®¾ç½®segmentå¼€å§‹æ—¶é—´
            if current_segment["start"] is None:
                current_segment["start"] = start_sec
            
            # æ·»åŠ è¯æ±‡åˆ°å½“å‰segment
            current_segment["text"] += word
            current_segment["end"] = end_sec
            current_segment["words"].append({
                "word": word,
                "start": start_sec,
                "end": end_sec
            })
            
            # åˆ¤æ–­æ˜¯å¦åº”è¯¥ç»“æŸå½“å‰segmentï¼ˆé‡åˆ°å¥å·ã€é—®å·ã€æ„Ÿå¹å·ï¼‰
            if word in ['ã€‚', 'ï¼', 'ï¼Ÿ', '.', '!', '?',',','ï¼Œ'] or i == len(words) - 1:
                if current_segment["text"].strip():
                    segments.append({
                        "text": current_segment["text"],
                        "start": current_segment["start"],
                        "end": current_segment["end"],
                        "words": current_segment["words"]
                    })
                
                # é‡ç½®å½“å‰segment
                current_segment = {
                    "text": "",
                    "start": None,
                    "end": None,
                    "words": []
                }
        
        return segments

    def get_supported_languages(self) -> List[str]:
        """
        è·å–æ”¯æŒçš„è¯­è¨€åˆ—è¡¨
        
        Returns:
            List[str]: æ”¯æŒçš„è¯­è¨€ä»£ç åˆ—è¡¨
        """
        return ["auto", "zh", "en", "ja", "ko", "es", "fr", "de", "it", "pt", "ru"]
    
    def format_transcription_output(self, result: Dict[str, Any], output_format: str = "text") -> str:
        """
        æ ¼å¼åŒ–è½¬å½•è¾“å‡º
        
        Args:
            result (Dict[str, Any]): è½¬å½•ç»“æœ
            output_format (str): è¾“å‡ºæ ¼å¼ ("text", "srt", "vtt", "json")
        
        Returns:
            str: æ ¼å¼åŒ–åçš„è¾“å‡º
        """
        if not result["success"]:
            return f"è½¬å½•å¤±è´¥: {result.get('error', 'æœªçŸ¥é”™è¯¯')}"
        
        if output_format == "text":
            return result["text"]
        
        elif output_format == "srt":
            return self._format_as_srt(result)
        
        elif output_format == "vtt":
            return self._format_as_vtt(result)
        
        elif output_format == "json":
            import json
            return json.dumps(result, ensure_ascii=False, indent=2)
        
        else:
            return result["text"]
    
    def _format_as_srt(self, result: Dict[str, Any]) -> str:
        """æ ¼å¼åŒ–ä¸ºSRTå­—å¹•æ ¼å¼"""
        srt_content = ""
        
        # ä¼˜å…ˆä½¿ç”¨formatted_segmentsï¼ˆå¸¦æ—¶é—´æˆ³ï¼‰
        if "formatted_segments" in result and result["formatted_segments"]:
            segments = result["formatted_segments"]
            for segment in segments:
                start_time = self._seconds_to_srt_time(segment["start_time"])
                end_time = self._seconds_to_srt_time(segment["end_time"])
                
                srt_content += f"{segment['index']}\n"
                srt_content += f"{start_time} --> {end_time}\n"
                srt_content += f"{segment['text']}\n\n"
        
        # ä½¿ç”¨çœŸå®æ—¶é—´æˆ³çš„segments
        elif "segments" in result and result["segments"]:
            segments = result["segments"]
            
            for i, segment in enumerate(segments):
                if isinstance(segment, dict) and "start" in segment and "end" in segment:
                    # ä½¿ç”¨FunASRè¿”å›çš„çœŸå®æ—¶é—´æˆ³
                    start_time = self._seconds_to_srt_time(segment["start"])
                    end_time = self._seconds_to_srt_time(segment["end"])
                    text = segment.get("text", "")
                    
                    srt_content += f"{i + 1}\n"
                    srt_content += f"{start_time} --> {end_time}\n"
                    srt_content += f"{text}\n\n"
        
        # æœ€åå…œåº•ï¼šä½¿ç”¨å…¨æ–‡æœ¬ï¼Œæ™ºèƒ½åˆ†å¥
        else:
            text = result.get("text", "")
            if text:
                # æ”¹è¿›çš„å¥å­åˆ†å‰²ï¼šåŒæ—¶æŒ‰å¥å·ã€é—®å·ã€æ„Ÿå¹å·åˆ†å‰²
                sentences = re.split(r'[ã€‚ï¼ï¼Ÿ.!?]', text)
                sentences = [s.strip() for s in sentences if s.strip()]
                
                current_time = 0
                for i, sentence in enumerate(sentences):
                    # æ ¹æ®å¥å­é•¿åº¦åŠ¨æ€è®¡ç®—æ—¶é—´
                    duration = max(2.0, len(sentence) * 0.4)  # æœ€å°‘2ç§’
                    start_time = self._seconds_to_srt_time(current_time)
                    end_time = self._seconds_to_srt_time(current_time + duration)
                    current_time += duration
                    
                    # æ¢å¤æ ‡ç‚¹ç¬¦å·
                    if not sentence.endswith(('ã€‚', 'ï¼', 'ï¼Ÿ', '.', '!', '?')):
                        sentence += 'ã€‚'
                    
                    srt_content += f"{i + 1}\n"
                    srt_content += f"{start_time} --> {end_time}\n"
                    srt_content += f"{sentence}\n\n"
        
        return srt_content
    
    def _format_as_vtt(self, result: Dict[str, Any]) -> str:
        """æ ¼å¼åŒ–ä¸ºVTTå­—å¹•æ ¼å¼"""
        vtt_content = "WEBVTT\n\n"
        
        # ä¼˜å…ˆä½¿ç”¨formatted_segmentsï¼ˆå¸¦æ—¶é—´æˆ³ï¼‰
        if "formatted_segments" in result and result["formatted_segments"]:
            segments = result["formatted_segments"]
            for segment in segments:
                start_time = self._seconds_to_vtt_time(segment["start_time"])
                end_time = self._seconds_to_vtt_time(segment["end_time"])
                
                vtt_content += f"{start_time} --> {end_time}\n"
                vtt_content += f"{segment['text']}\n\n"
        
        # ä½¿ç”¨åŸå§‹segmentsä¸­çš„çœŸå®æ—¶é—´æˆ³
        elif "segments" in result and result["segments"]:
            segments = result["segments"]
            for i, segment in enumerate(segments):
                if isinstance(segment, dict):
                    # å¦‚æœæœ‰çœŸå®çš„æ—¶é—´æˆ³ï¼Œä½¿ç”¨å®ƒä»¬
                    if "start" in segment and "end" in segment:
                        start_time = self._seconds_to_vtt_time(segment["start"])
                        end_time = self._seconds_to_vtt_time(segment["end"])
                    else:
                        # å¦åˆ™æ ¹æ®æ®µè½é•¿åº¦ä¼°ç®—æ›´åˆç†çš„æ—¶é—´
                        text = segment.get("text", "")
                        duration = max(2.0, len(text) * 0.4)
                        start_time = self._seconds_to_vtt_time(i * duration)
                        end_time = self._seconds_to_vtt_time((i + 1) * duration)
                    
                    text = segment.get("text", str(segment))
                else:
                    # å­—ç¬¦ä¸²ç±»å‹çš„segment
                    text = str(segment)
                    duration = max(2.0, len(text) * 0.4)
                    start_time = self._seconds_to_vtt_time(i * duration)
                    end_time = self._seconds_to_vtt_time((i + 1) * duration)
                
                vtt_content += f"{start_time} --> {end_time}\n"
                vtt_content += f"{text}\n\n"
        
        # æœ€åå…œåº•ï¼šä½¿ç”¨å…¨æ–‡æœ¬ï¼Œæ™ºèƒ½åˆ†å¥
        else:
            text = result.get("text", "")
            if text:
                # æ”¹è¿›çš„å¥å­åˆ†å‰²
                sentences = re.split(r'[ã€‚ï¼ï¼Ÿ.!?]', text)
                sentences = [s.strip() for s in sentences if s.strip()]
                
                current_time = 0
                for i, sentence in enumerate(sentences):
                    # æ ¹æ®å¥å­é•¿åº¦åŠ¨æ€è®¡ç®—æ—¶é—´
                    duration = max(2.0, len(sentence) * 0.4)
                    start_time = self._seconds_to_vtt_time(current_time)
                    end_time = self._seconds_to_vtt_time(current_time + duration)
                    current_time += duration
                    
                    # æ¢å¤æ ‡ç‚¹ç¬¦å·
                    if not sentence.endswith(('ã€‚', 'ï¼', 'ï¼Ÿ', '.', '!', '?')):
                        sentence += 'ã€‚'
                    
                    vtt_content += f"{start_time} --> {end_time}\n"
                    vtt_content += f"{sentence}\n\n"
        
        return vtt_content
    
    def _seconds_to_srt_time(self, seconds: float) -> str:
        """å°†ç§’æ•°è½¬æ¢ä¸ºSRTæ—¶é—´æ ¼å¼"""
        hours = int(seconds // 3600)
        minutes = int((seconds % 3600) // 60)
        secs = int(seconds % 60)
        millisecs = int((seconds - int(seconds)) * 1000)
        return f"{hours:02d}:{minutes:02d}:{secs:02d},{millisecs:03d}"
    
    def _seconds_to_vtt_time(self, seconds: float) -> str:
        """å°†ç§’æ•°è½¬æ¢ä¸ºVTTæ—¶é—´æ ¼å¼"""
        hours = int(seconds // 3600)
        minutes = int((seconds % 3600) // 60)
        secs = seconds % 60
        return f"{hours:02d}:{minutes:02d}:{secs:06.3f}"
    
    def _get_audio_info(self, audio_path: str) -> Dict[str, Any]:
        """
        è·å–éŸ³é¢‘æ–‡ä»¶ä¿¡æ¯
        
        Args:
            audio_path (str): éŸ³é¢‘æ–‡ä»¶è·¯å¾„
            
        Returns:
            Dict[str, Any]: éŸ³é¢‘ä¿¡æ¯
        """
        try:
            import soundfile as sf
            data, samplerate = sf.read(audio_path)
            duration = len(data) / samplerate
            return {
                "duration": duration,
                "sample_rate": samplerate,
                "channels": data.shape[1] if len(data.shape) > 1 else 1,
                "samples": len(data)
            }
        except Exception as e:
            raise Exception(f"æ— æ³•è¯»å–éŸ³é¢‘æ–‡ä»¶ä¿¡æ¯: {str(e)}")
    
